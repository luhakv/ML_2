{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Юнит 7. Основные алгоритмы машинного обучения. Часть II \n",
    "### Skillfactory: DSPR-19\n",
    "### ML-7. Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кластеризация** — это задача разбиения некого количества объектов на группы (кластеры), при этом объекты в группах должны иметь что-то общее и сильно отличаться от объектов в других кластерах. Перечень групп определяется в процессе работы алгоритма, а не заранее. Задача кластеризации является задачей обучения без учителя.\n",
    "\n",
    "По сути, кластеризация очень похожа на задачу классификации, но без известных заранее классов. Алгоритм самостоятельно находит близкие по каким-то признакам точки и объединяет их в кластеры. Подобную операцию вы можете наблюдать, если будете искать какие-то часто встречающиеся объекты на карте.\n",
    "\n",
    "### 7.2. Задачи и подходы кластеризации\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача кластеризации: найти отображение множества входных объектов $X$, которое разделило бы множество $X$ на подгруппы. Кластеризация — это обучение без учителя.\n",
    "\n",
    "Формальная запись задачи кластеризации выглядит следующим образом:\n",
    "\n",
    "Пусть $X$ — множество объектов,  $Y$ — множество метод кластеров (идентификаторов их принадлежности). На множестве $X$ задана функция, которая вычисляет расстояние между объектами:\n",
    "\n",
    "$\\rho\\left(x, x^{\\prime}\\right)$. \n",
    "\n",
    "Также дана конечная обучающая выборка объектов: $X^{m}=\\left\\{x_{1}, \\ldots, x_{m}\\right\\} \\subset X$ \n",
    "\n",
    "Нам надо разбить выборку на кластеры, то есть поставить каждому объекту $X$ в соответствие метку $y_{i} \\in Y$ так, чтобы внутри каждого кластера объекты были как можно более близки (то есть расстояние должно быть минимальным), а объекты из разных кластеров значительно различались.\n",
    "\n",
    "В задаче кластеризации входные данные задаются двумя способами:\n",
    "\n",
    "- Признаковое описание объектов: все объекты описываются некоторыми характеристиками (значениями признаков)\n",
    "- Матрица расстояний между объектами: для каждого объекта представлены расстояния от него до всех остальных\n",
    "объектов выборки\n",
    "\n",
    "**Некорректность задачи кластеризации** — решение задачи кластеризации принципиально неоднозначно:\n",
    "\n",
    "- Нет **точной постановки** задачи кластеризации.\n",
    "- Существует **множество критериев** качества кластеризации.\n",
    "- Существует **множество методов** кластеризации.\n",
    "- Часто заранее **неизвестно число кластеров**.\n",
    "- Результат кластеризации зависит от **метрики**, которая **задаётся субъективно**.\n",
    "\n",
    "**Разные цели кластеризации:**\n",
    "- Упростить дальнейшую обработку данных: разбить множество объектов на несколько групп (кластеров), чтобы в дальнейшем работать с каждым кластером в отдельности\n",
    "- Сократить объём хранимых данных: выделить кластеры и оставить по одному объекту от каждого кластера и таким образом сжать данные\n",
    "- Выделить нетипичные объекты: выделить объекты, которые нельзя отнести ни к одному из кластеров\n",
    "- Построить иерархию множества объектов: задача таксономии.  \n",
    "\n",
    "**Разнообразие условий задач кластеризации.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.2.1\n",
    "Чем отличается кластеризация от классификации?  \n",
    "\n",
    "Ответ:  \n",
    "- ластеризация работает с неразмеченными данными, классификация — с размеченными верно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.2.2\n",
    "Выберите, что из приведённого является целями кластеризации  \n",
    "\n",
    "Ответ:  \n",
    "- Выделить нетипичные объекты\n",
    "- Сократить объём хранимых данных\n",
    "- Построить иерархию множества объектов\n",
    "\n",
    "Какие из перечисленных задач можно решить с помощью кластеризации?\n",
    "\n",
    "Ответ:  \n",
    "- сегментация покупаталей\n",
    "- поиск схожих по характеристикам компаний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Условия задач кластеризации\n",
    "\n",
    "**Форма кластеров**: внутрикластерные расстояния меньше межкластерных, ленточная структура, кластеры с центром, кластеры соединены перемычками, разреженный фон, пересекающиеся кластеры, кластеры отсутствуют, кластеры образуются не по близости расстояний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вложенность кластеров** друг в друга.  \n",
    "**Размер кластеров:** один кластер — одна тема, один кластер — одно большое событие, один кластер — одна новость.  \n",
    "**Кластеризация как основная или вспомогательная задача.**  \n",
    "**Жёсткая** _(определяем конкретный кластер для объекта)_ или **мягкая** _(определяем вероятность принадлежности объекта к кластеру)_ кластеризация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.3.1\n",
    "Выберите задачи, для которых кластеризация является основой:\n",
    "\n",
    "Ответ:  \n",
    "- Сегментация покупателей\n",
    "- Кластеризация новостных текстов\n",
    "- Кластеризация изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.3.2\n",
    "С помощью какого типа кластеризации можно получить результат, что статья \"Contour-Aware Multi-Label X-ray Organ Segmentation\" относится к теме Deep Learning с вероятностью 0.7, к теме Medicine с вероятностью 0.3?\n",
    "\n",
    "Ответ:  \n",
    "- Мягкая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. Алгоритмы кластеризации\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим четыре основных алгоритма кластеризации:\n",
    "\n",
    "_k-means_  \n",
    "_EM-алгоритм_  \n",
    "_DBSCAN_  \n",
    "_агломеративная кластеризация_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-MEANS\n",
    "**k-means** является одним из самых популярных и простых алгоритмов кластеризации. В ходе этого алгоритма все элементы пространства разбиваются на заранее известное (заданное) количество кластеров. Суть алгоритма состоит в том, что он пытается оптимизировать расстояние всех точек кластера от центра этого кластера. То есть он формирует кластеры так, чтобы внутри каждого сумма квадратов расстояний от точек до центра кластера была как можно меньше.\n",
    "\n",
    "**Схема действия алгоритма k-means**\n",
    "\n",
    "- Выбрать количество кластеров, которое нам кажется оптимальным для наших данных.\n",
    "- Выбрать случайным образом в пространство наших данных центроиды.\n",
    "- Для каждой точки набора данных посчитать, к какому центроиду она ближе.\n",
    "- Переместить каждый центроид в центр выборки, которую мы отнесли к этому центроиду. Каждый центроид на каждой итерации — вектор, элементы которого представляют собой средние значения признаков, вычисленные по всем записям кластера.\n",
    "- Повторять шаги 3-4 фиксированное число раз или до тех пор, пока центроиды не сойдутся.\n",
    "\n",
    "**У этого алгоритма есть ряд недостатков:**\n",
    "\n",
    "- число кластеров надо знать заранее;\n",
    "- алгоритм очень чувствителен к первичному выбору центроидов;\n",
    "- не гарантирует достижение глобального минимума суммы квадратов расстояний, часто «застревает» в локальном минимуме.\n",
    "\n",
    "**Mini-Batch K-means**  \n",
    "Данная вариация _k-means_ используется в случае, если данных очень много. Из-за объема данных вычисление центров по всей выборке происходит долго. Решение проблемы: на каждом шаге k-means работать с небольшой подвыборкой данных. В общем случае упрощённый алгоритм должен сходиться к тому же результату, что и на полной выборке. Однако исследования показывают, что качество кластеров может ухудшаться по сравнению с классическим k-means.\n",
    "\n",
    "**K-means++**  \n",
    "Ещё одну вариацию алгоритма k-means мы используем в том случае, если у нас очень много признаков. Как известно, результат и время работы k-means зависит от изначального выбора центров. Чтобы минимизировать затраты, мы будем действовать следующим образом:\n",
    "\n",
    "- Первый центр выбираем случайно из равномерного распределения на выборке.\n",
    "- Каждый следующий центр выбираем случайно из оставшихся точек так, чтобы вероятность выбрать каждую точку была пропорциональна квадрату расстояния от неё до ближайшего центра.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-АЛГОРИТМ\n",
    "\n",
    "Следующий алгоритм кластеризации — **EM-алгоритм**. Последовательность действий в нём выглядит следующим образом:\n",
    "\n",
    "**Схема действий EM-алгоритма**\n",
    "\n",
    "- Выбрать количество кластеров, которое нам кажется оптимальным для наших данных.\n",
    "- Выбрать случайным образом в пространство наших данных параметры распределений.\n",
    "- Для каждой точки нашего набора данных посчитать вероятность принадлежности к каждому кластеру.\n",
    "- Обновить параметры распределений таким образом, чтобы максимизировать вероятность принадлежности точек, отнесённых к кластеру.\n",
    "- Повторять шаги 3-4 фиксированное число раз, либо до тех пор пока центроиды не сойдутся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Можно выделить следующие преимущества алгоритма:**\n",
    "\n",
    "- Эффективная обработка больших объемов данных (Big Data).\n",
    "- Мощная статистическая основа.\n",
    "- Устойчивость к шумам и пропускам в данных.\n",
    "- Возможность построения желаемого числа кластеров.\n",
    "- Быстрая сходимость при удачной инициализации.\n",
    "\n",
    "**Недостатки алгоритма следующие:**\n",
    "\n",
    "- При неудачной инициализации сходимость алгоритма может оказаться медленной.\n",
    "- Предположение о нормальности всех измерений данных не всегда выполняется.\n",
    "- Алгоритм иногда останавливается в локальном минимуме и не достигает глобального."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### АГЛОМЕРАТИВНАЯ КЛАСТЕРИЗАЦИЯ\n",
    "Иерархическая кластеризация делится на две стратегии: **агломеративная** — снизу-вверх, объединяем точки в кластеры и **дивизионная** — сверху-вниз, разделяем один большой кластер на малые.\n",
    "\n",
    "- Назначаем каждой точке свой кластер.\n",
    "- Сортируем попарные расстояния между центрами кластеров по возрастанию.\n",
    "- Берём пару ближайших кластеров, склеиваем их в один и пересчитываем центр кластера.\n",
    "- Повторяем шаги 2-3 до тех пор, пока все данные не склеятся в один кластер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "Расшифровывается как **Dense-based spatial clustering of applications with noise**. Это основанная на плотности пространственная кластеризация для приложений с шумами.\n",
    "\n",
    "**Схема действия DBSCAN**\n",
    "\n",
    "- Случайно выбираем точку, которую не посещали. Окрестность точки извлекается с использованием расстояния .\n",
    "- Если в этой окрестности точек ≥ minPoints, тогда точка становится первой точкой в новом кластере. Иначе — помечаем точку как шум, она становится посещённой.\n",
    "- Точки из окрестности становятся частью кластера. Для каждой из них изучаем окрестность: если точек в окрестности < minPoints, то помечаем точку как граничную.\n",
    "- Повторяем пункты 2 и 3, пока не определим все точки в кластере.\n",
    "- Повторяем пункты 1–4, пока все точки не станут просмотренными.\n",
    "\n",
    "**Главная идея:**  \n",
    "\n",
    "- Основные точки.\n",
    "- Граничные точки.\n",
    "- Шумовые точки.\n",
    "\n",
    "\n",
    "**Достоинства алгоритма:**\n",
    "\n",
    "- не требуется число кластеров;\n",
    "- определяем кластеры произвольной формы;\n",
    "- определяет шум, устойчив к выбросам.\n",
    "\n",
    "\n",
    "**Недостатки алгоритма:**\n",
    "\n",
    "- не может выделять кластеры, имеющие разную плотность;\n",
    "- результат зависит от используемой функции расстояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
